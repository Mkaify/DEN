{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kaifu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Multinomial Naive Bayes ---\n",
      "Accuracy: 0.9659192825112107\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.75      0.85       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.87      0.92      1115\n",
      "weighted avg       0.97      0.97      0.96      1115\n",
      "\n",
      "Confusion Matrix:\n",
      " [[965   0]\n",
      " [ 38 112]]\n",
      "\n",
      "\n",
      "--- Logistic Regression ---\n",
      "Accuracy: 0.9551569506726457\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       965\n",
      "           1       0.96      0.69      0.81       150\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.96      0.84      0.89      1115\n",
      "weighted avg       0.96      0.96      0.95      1115\n",
      "\n",
      "Confusion Matrix:\n",
      " [[961   4]\n",
      " [ 46 104]]\n",
      "\n",
      "\n",
      "--- Support Vector Machine ---\n",
      "Accuracy: 0.9775784753363229\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.99      0.84      0.91       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Confusion Matrix:\n",
      " [[964   1]\n",
      " [ 24 126]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Email Spam Classification - Week 03 Task\n",
    "\n",
    "# Section 1: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Section 2: Load Dataset\n",
    "# Replace with your dataset path\n",
    "data = pd.read_csv(\"spam.csv\", encoding='latin-1')[['v1', 'v2']]\n",
    "data.columns = ['label', 'message']\n",
    "\n",
    "# Section 3: Preprocessing\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text = text.split()\n",
    "    ps = PorterStemmer()\n",
    "    text = [ps.stem(word) for word in text if word not in stopwords.words('english')]\n",
    "    return \" \".join(text)\n",
    "\n",
    "data['clean_message'] = data['message'].apply(clean_text)\n",
    "data['label_num'] = data['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Section 4: Vectorization\n",
    "cv = CountVectorizer()\n",
    "x_count = cv.fit_transform(data['clean_message'])\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "x_tfidf = tfidf.fit_transform(data['clean_message'])\n",
    "\n",
    "y = data['label_num']\n",
    "\n",
    "# Section 5: Train-Test Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Section 6: Model Building & Evaluation\n",
    "def evaluate_model(model, name):\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, preds))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "evaluate_model(MultinomialNB(), \"Multinomial Naive Bayes\")\n",
    "\n",
    "# Logistic Regression\n",
    "evaluate_model(LogisticRegression(max_iter=1000), \"Logistic Regression\")\n",
    "\n",
    "# Support Vector Machine\n",
    "evaluate_model(SVC(), \"Support Vector Machine\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ca641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
